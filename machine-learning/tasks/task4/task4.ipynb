{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 Data Preprocessing and Exploratory Data Analysis\n",
    "\n",
    "We perform the following steps:\n",
    "1. Load the dataset (\"Dataset.csv\") and verify its integrity.\n",
    "2. Confirm that there are no missing values.\n",
    "3. Identify and analyze outliers using visualizations such as boxplots.\n",
    "4. Visualize feature distributions with histograms and KDE plots to understand the\n",
    "overall distribution of each feature.\n",
    "5. Review feature statistics (e.g., mean, standard deviation) to get insights into the\n",
    "data.\n",
    "6. Normalize or standardize the dataset so that all features contribute equally in\n",
    "distance calculations, which is crucial for clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 1: Load the dataset (\"Dataset.csv\") and verify its integrity.\n",
    "\n",
    "Manual inspection of the dataset determined that there are 900 rows (excluding the header row) and 8 columns. There to satisfy the integrity requirement we take that to mean the row and column counts are equal after the dataframe is loaded.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Dataset.csv\") # load the dataset\n",
    "rows, cols = df.shape # get the row and column counts\n",
    "print(f\"Dataset shape: {rows} rows, {cols} columns\") \n",
    "\n",
    "# programmatic verification of the integrity of the dataset, throw an error if the row or column counts are not equal to 900 and 8 respectively\n",
    "if rows != 900:\n",
    "    assert False, \"The number of rows in the dataset is not equal to 900\"\n",
    "if cols != 8:\n",
    "    assert False, \"The number of columns in the dataset is not equal to 8\"\n",
    "\n",
    "print(\"Dataset integrity verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 2: Confirm that there are no missing values.\n",
    "Count the number of missing values in each column and throw an error if any are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "if missing_values_count.sum() > 0:\n",
    "    assert False, \"The dataset contains missing values!!!! FIX\"\n",
    "print(\"Good, No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 3: Identify and analyze outliers using visualizations such as boxplots.\n",
    "Boxplots for each numerical feature to identify and analyze outliers. Calculate and display statistics about potential outliers. This can be done by calculating the IQR and then using that to identify the lower and upper bounds of the outliers.\n",
    "The label is categorical so not included in outlier detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_palette('viridis') # set colour scheme\n",
    "\n",
    "# Get numerical features from the dataset\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Create boxplots for each numerical feature\n",
    "plt.figure(figsize=(16, 10))\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    plt.subplot(3, 3, i+1)  # Adjust grid based on number of features\n",
    "    sns.boxplot(y=df[feature])\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Boxplots for Numerical Features to Identify Outliers', fontsize=16)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display statistics about outliers\n",
    "print(\"Potential outliers analysis:\")\n",
    "for feature in numerical_features:\n",
    "    Q1 = df[feature].quantile(0.25)\n",
    "    Q3 = df[feature].quantile(0.75)\n",
    "\n",
    "    # A standard way to detect outliers is to use the IQR (Interquartile Range) then outliers are any values that fall outside of 1.5 times the IQR below Q1 or above Q3\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)][feature]\n",
    "    print(f\"{feature}: {len(outliers)} outliers detected\")\n",
    "    if len(outliers) > 0:\n",
    "        print(f\"  - Min Boundary: {outliers.min():.2f}, Max Boundary {outliers.max():.2f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 4: Visualize feature distributions with histograms and KDE plots to understand the overall distribution of each feature.\n",
    "\n",
    "Seaborn has differing functions for histograms and KDE plots. Use these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns # list of numerical features\n",
    "\n",
    "# Display histograms for each numerical feature\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    plt.subplot(3, 3, i+1)  # Adjust grid based on number of features\n",
    "    sns.histplot(df[feature])\n",
    "    plt.title(f'Histogram of {feature}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Feature Distributions with Histograms', fontsize=16)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "\n",
    "# Create KDE plots for each numerical feature\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Get numerical features from the dataset\n",
    "numerical_features = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "# Create KDE plots for each numerical feature\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    plt.subplot(3, 3, i+1)  # Adjust grid based on number of features\n",
    "    sns.kdeplot(df[feature], fill=True)\n",
    "    plt.title(f'KDE Plot of {feature}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Feature Distributions with KDE Plots', fontsize=16)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features are skewed to either the left or right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 5 - Review feature statistics (e.g., mean, standard deviation) to get insights into the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Basic Statistics for Numerical Features via Pandas Dataframe describe:\")\n",
    "display(df.describe())\n",
    "\n",
    "# Calculate additional statistics that aren't in describe()\n",
    "print(\"\\nAdditional Statistics:\")\n",
    "numerical_stats = pd.DataFrame({\n",
    "    'Median': df.select_dtypes(include=[np.number]).median(),\n",
    "    'Skewness': df.select_dtypes(include=[np.number]).skew(),\n",
    "    'Kurtosis': df.select_dtypes(include=[np.number]).kurt(),\n",
    "    'IQR': df.select_dtypes(include=[np.number]).quantile(0.75) - df.select_dtypes(include=[np.number]).quantile(0.25),\n",
    "    'Range': df.select_dtypes(include=[np.number]).max() - df.select_dtypes(include=[np.number]).min()\n",
    "})\n",
    "display(numerical_stats)\n",
    "\n",
    "# Generate a correlation matrix\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "correlation_matrix = df.select_dtypes(include=[np.number]).corr()\n",
    "display(correlation_matrix)\n",
    "\n",
    "# Plot the correlation matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Numerical Features')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that lengths and areas are highly correlated, which is expected as area is a function of length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 6 - Normalize or standardize the dataset so that all features contribute equally in distance calculations, which is crucial for clustering.\n",
    "\n",
    "For every numeric feature, we will normalize it to a range of 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Min-Max normalization to scale features to [0,1] range\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "\n",
    "print(\"Data has been normalized to the range [0,1]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
