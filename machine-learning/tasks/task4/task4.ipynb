{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import silhouette_score, normalized_mutual_info_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score, v_measure_score, silhouette_score, davies_bouldin_score, mutual_info_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "from collections import Counter\n",
    "from scipy.spatial.distance import pdist, squareform, mahalanobis\n",
    "from numpy.linalg import inv, pinv\n",
    "from kneed import KneeLocator\n",
    "import warnings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 EDA and Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 1: Data loading\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Subtask 1 - Data Loading\n",
    "#\n",
    "# Purpose: Load the dataset into a pandas dataframe and verify row and column counts\n",
    "# Takeaway: The validated dataset will be loaded.\n",
    "########\n",
    "df = pd.read_csv(\"Dataset.csv\") # load the dataset\n",
    "rows, cols = df.shape # get the row and column counts\n",
    "print(f\"Dataset shape: {rows} rows, {cols} columns\") \n",
    "\n",
    "# programmatic verification of the integrity of the dataset, throw an error if the row or column counts are not equal to 900 and 8 respectively\n",
    "if rows != 900:\n",
    "    assert False, \"Row count != 900\"\n",
    "if cols != 8:\n",
    "    assert False, \"Column count != 8\"\n",
    "\n",
    "print(\"Dataset integrity verified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 2: Check for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Subtask 2 - Verify that there are no missing values.\n",
    "# \n",
    "# Purpose: Check all columns and rows for missing values.\n",
    "# Takeaway: There are no missing data points or values in the dataset.\n",
    "########\n",
    "no_missing = df.isnull().sum()\n",
    "if no_missing.sum() > 0:\n",
    "    assert False, \"The dataset contains missing values!!!! FIX\"\n",
    "print(\"Good, No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 3: Outlier visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Subtask 3 - Outlier visualisation\n",
    "#\n",
    "# Purpose: Generate boxplots for each numerical column so that manual inspection for outliers can be done.\n",
    "# Takeaway: Boxplots for each numerical feature was generated. Most features have outliers.        \n",
    "########\n",
    "\n",
    "sns.set_palette('viridis') # set colour scheme\n",
    "\n",
    "# Get numerical ds_feats from the dataset (only numerical features are considered for outlier detection)\n",
    "num_features = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "plt.figure(figsize=(16, 10))\n",
    "for i, ds_feat in enumerate(num_features):\n",
    "    plt.subplot(3, 3, i+1)  # Adjust grid based on number of features\n",
    "    sns.boxplot(y=df[ds_feat])\n",
    "    plt.title(f'{ds_feat} Boxplot')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Boxplots for Numerical Features to Identify Outliers', fontsize=16)\n",
    "plt.subplots_adjust(top=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 4: Distribution Visualisations\n",
    "\n",
    "Seaborn has differing functions for histograms and KDE plots. Use these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Subtask 4: Distribution Visualisations\n",
    "#\n",
    "# Purpose: Generate histograms and KDS plots for each feature to visualise their distributions.\n",
    "# Takeaway: The following features can be seen to be right skewed: Area, ConvexArea, MajorAxisLength, MinorAxisLength, Perimeter. \n",
    "#            The following features are left skewed: Eccentricity, Extent.\n",
    "########\n",
    "\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Histogram for each feature\n",
    "for i, feature in enumerate(num_features):\n",
    "    plt.subplot(3, 3, i+1)  \n",
    "    sns.histplot(df[feature])\n",
    "    plt.title(f'{feature} Histogram')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Per feature histogram', fontsize=14)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# KDE plot per feature\n",
    "for i, feature in enumerate(num_features):\n",
    "    plt.subplot(3, 3, i+1)  \n",
    "    sns.kdeplot(df[feature], fill=True)\n",
    "    plt.title(f'{feature} KDE Plot')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.suptitle('Per Feature KDE Plot', fontsize=16)\n",
    "plt.subplots_adjust(top=0.9)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numeric features have a skew either to the left or the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 5 - Statistical descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Subtask 5 - Statistical descriptors\n",
    "#\n",
    "# Purpose: Produce descriptive statistics for each numerical feature and comment on them..\n",
    "# Takeaway: The descriptive statistics show that the following features are right skewed: Area, ConvexArea, MajorAxisLength, MinorAxisLength, Perimeter, as their mean is larger than the median.\n",
    "#           The following features are left skewed: Eccentricity, Extent, as their mean is less than the median.\n",
    "########\n",
    "\n",
    "print(\"Descriptive statistics.\")\n",
    "display(df.describe())\n",
    "\n",
    "# Calculate additional statistics that aren't in describe()\n",
    "print(\"\\nAdditional Statistics:\")\n",
    "numerical_stats = pd.DataFrame({\n",
    "    'Median': df.select_dtypes(include=[np.number]).median(),\n",
    "    'Skewness': df.select_dtypes(include=[np.number]).skew(),\n",
    "    'Kurtosis': df.select_dtypes(include=[np.number]).kurt(),\n",
    "    'IQR': df.select_dtypes(include=[np.number]).quantile(0.75) - df.select_dtypes(include=[np.number]).quantile(0.25),\n",
    "    'Range': df.select_dtypes(include=[np.number]).max() - df.select_dtypes(include=[np.number]).min()\n",
    "})\n",
    "display(numerical_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtask 6 - Dataset Normalisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Subtask 6 - Dataset Normalisation\n",
    "#\n",
    "# Purpose: For every numeric feature, change the range of values to fit between 0 and 1 while preserving the shape of the distribution.\n",
    "# Takeaway: All numeric features were normalised.\n",
    "########\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist() # create list of numerical columns\n",
    "minmax_scaler = MinMaxScaler()\n",
    "df[num_cols] = minmax_scaler.fit_transform(df[num_cols]) # fit then transform the numerical columns\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Inspect the Effect of Cluster Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########\n",
    "# Task 2 - Inspect the Effect of Cluster Count\n",
    "#\n",
    "# Purpose: To determine, using the elbow method, the optimal cluster number.\n",
    "# Takeaway: 3 was to be determined the optimal cluster number, as this is where the elbow is.\n",
    "########\n",
    "\n",
    "model = KMeans()\n",
    "visualiser = KElbowVisualizer(\n",
    "    model, k=(1,11), metric='distortion', timings=False\n",
    ") \n",
    "\n",
    "visualiser.fit(df[num_cols])        # Fit the data to the visualizer\n",
    "visualiser.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 - Inspect Effects of Cluster Initialisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########\n",
    "# Task 3 - Inspect Effects of Cluster Initialisation\n",
    "#\n",
    "# Purpose: Run KMeans and Kmeans++ clustering many times to investigate if rand initialisation has an effect on the clustering results.\n",
    "# Takeaway: It was observed that Kmeans++ had a greater dispersion for its distribution of results for both inertia and silhouette scores. This indicates\n",
    "#           that it is more affected by rand initialisation values than KMeans.\n",
    "##########\n",
    "\n",
    "loop_count = 50\n",
    "cluster_count = 3  # Using 5 clusters based on the elbow method from previous task\n",
    "vanilla_inertias = []\n",
    "vanilla_silhouette_scores = []\n",
    "fancy_kmeans_inertias = []\n",
    "fancy_kmeans_silhouette_scores = []\n",
    "\n",
    "for magic_number in range(loop_count): \n",
    "\n",
    "    # kmeans\n",
    "    boring_kmeans = KMeans(n_clusters=cluster_count, init='random', random_state=magic_number)\n",
    "    boring_kmeans.fit(df[num_cols])\n",
    "    vanilla_inertias.append(boring_kmeans.inertia_)\n",
    "    \n",
    "    # kmeans++\n",
    "    fancy_kmeans = KMeans(n_clusters=cluster_count, init='k-means++', random_state=magic_number)\n",
    "    fancy_kmeans.fit(df[num_cols])\n",
    "    fancy_kmeans_inertias.append(fancy_kmeans.inertia_)\n",
    "    \n",
    "    # calc silhouette score for kmeans++\n",
    "    fancy_labels = fancy_kmeans.labels_\n",
    "    fancy_kmeans_silhouette_scores.append(silhouette_score(df[num_cols], fancy_labels))\n",
    "\n",
    "# calc average metrics\n",
    "vanilla_inertia_avg = np.mean(vanilla_inertias)\n",
    "vanilla_silhouette_avg = np.mean(vanilla_silhouette_scores)\n",
    "fancy_inertia_avg = np.mean(fancy_kmeans_inertias)\n",
    "fancy_silhouette_avg = np.mean(fancy_kmeans_silhouette_scores)\n",
    "\n",
    "# calc standard deviations \n",
    "vanilla_inertia_wobble = np.std(vanilla_inertias)\n",
    "vanilla_silhouette_wobble = np.std(vanilla_silhouette_scores)\n",
    "fancy_inertia_wobble = np.std(fancy_kmeans_inertias)\n",
    "fancy_silhouette_wobble = np.std(fancy_kmeans_silhouette_scores)\n",
    "\n",
    "# Display results\n",
    "print(\"Kmeans Initialisation:\")\n",
    "print(f\"Average Inertia: {vanilla_inertia_avg:.2f} (±{vanilla_inertia_wobble:.2f})\")\n",
    "print(f\"Average Silhouette Score: {vanilla_silhouette_avg:.4f} (±{vanilla_silhouette_wobble:.4f})\")\n",
    "print(\"\\nKMeans++ Initialisation:\")\n",
    "print(f\"Average Inertia: {fancy_inertia_avg:.2f} (±{fancy_inertia_wobble:.2f})\")\n",
    "print(f\"Average Silhouette Score: {fancy_silhouette_avg:.4f} (±{fancy_silhouette_wobble:.4f})\")\n",
    "\n",
    "# Plot the distribution of inertias for both methods\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(vanilla_inertias, alpha=0.7, label='Random Init')\n",
    "plt.hist(fancy_kmeans_inertias, alpha=0.7, label='KMeans++ Init')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Metric - Inertia')\n",
    "plt.title('Dist of Inertia Values')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(vanilla_silhouette_scores, alpha=0.7, label='Random Init')\n",
    "plt.hist(fancy_kmeans_silhouette_scores, alpha=0.7, label='KMeans++ Init')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Metric - Silhouette Score')\n",
    "\n",
    "plt.title('Dist of Silhouette Scores')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Task 4 - Investigate Various Cluster Evaluation Methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 4 - Investigate Various Cluster Evaluation Methods\n",
    "#\n",
    "# Purpose: To investigate and evaluate various clustering evaluation methods and metrics.\n",
    "# Takeaway: A purity score of 0.84 is not far off the highest score of 1 indicating that the points assigned to the cluster had good agreement with the ground truth labels.\n",
    "#           A mutual information score of 0.3343 is not particularly high meaning that the clustering did not find the underlying structure of the data very well.\n",
    "#           A silhouette score of 0.3372 is once again not particularly high meanings that the boundaries between the clusters is not very clear.\n",
    "#########\n",
    "\n",
    "\n",
    "# 3 was the optimal k from task 2\n",
    "k = 3\n",
    "\n",
    "# get labels and features\n",
    "X = df.drop('label', axis=1)\n",
    "true_labels = df['label']\n",
    "\n",
    "# KMeans \n",
    "kmeans_model = KMeans(n_clusters=k, random_state=42, init='k-means++')\n",
    "kmeans_cluster_labels = kmeans_model.fit_predict(X)\n",
    "\n",
    "# based on majority class assign a label to each cluster\n",
    "cluster_to_label = {}\n",
    "for cluster_id in range(k):\n",
    "    cluster_index = np.where(kmeans_cluster_labels == cluster_id)[0]\n",
    "    cluster_true_labels = true_labels.iloc[cluster_index]\n",
    "    # get the most common label\n",
    "    common_label = Counter(cluster_true_labels).most_common(1)[0][0]\n",
    "    cluster_to_label[cluster_id] = common_label\n",
    "\n",
    "# print mappings\n",
    "print(\"Cluster to Label Mapping:\")\n",
    "for cluster_id, label in cluster_to_label.items():\n",
    "    print(f\"Cluster {cluster_id} has label: {label}\")\n",
    "\n",
    "def purity_score(ground_truth, predicted_clusters):\n",
    "    confusion_matrix = np.zeros((k, len(np.unique(ground_truth))))\n",
    "    \n",
    "    for idx in range(len(ground_truth)):\n",
    "        actual_label_idx = np.where(np.unique(ground_truth) == ground_truth.iloc[idx])[0][0]\n",
    "        confusion_matrix[predicted_clusters[idx], actual_label_idx] += 1\n",
    "    \n",
    "    return np.sum(np.max(confusion_matrix, axis=1)) / len(ground_truth)\n",
    "\n",
    "# calc evaluation metrics\n",
    "purity_metric = purity_score(true_labels, kmeans_cluster_labels)\n",
    "mutual_information = normalized_mutual_info_score(true_labels, kmeans_cluster_labels)\n",
    "silhouette_coefficient = silhouette_score(X, kmeans_cluster_labels)\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"Purity Score: {purity_metric:.4f}\")\n",
    "print(f\"Normalized Mutual Information Score: {mutual_information:.4f}\")\n",
    "print(f\"Silhouette Score: {silhouette_coefficient:.4f}\")\n",
    "\n",
    "# Graph clusters\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "for cluster_idx in range(k):\n",
    "    points_in_cluster = X[kmeans_cluster_labels == cluster_idx]\n",
    "    plt.scatter(points_in_cluster.iloc[:, 0], points_in_cluster.iloc[:, 1], \n",
    "                label=f\"Cluster {cluster_idx}: {cluster_to_label[cluster_idx]}\")\n",
    " \n",
    "for class_label in np.unique(true_labels):\n",
    "    points_with_label = X[true_labels == class_label]\n",
    "    plt.scatter(points_with_label.iloc[:, 0], points_with_label.iloc[:, 1], label=class_label)\n",
    "\n",
    "plt.title('True Labels')\n",
    "plt.xlabel(X.columns[0])\n",
    "plt.ylabel(X.columns[1])\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5 Investigate PCA and Variance Captured by Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######\n",
    "# Task 5 - Investigate PCA and Variance Captured by Components\n",
    "#\n",
    "# Purpose: To produce a new dataset using principal component analysis. The dimensionality will be reduced to 4 features.\n",
    "# Takeaway: 4 components were produced and it was determined that 3 components were needed to keep 90% of the variance:\n",
    "#           Component 1: 0.6903 \n",
    "#           Component: 0.2076 \n",
    "#           Component 3: 0.0898 98% of variance\n",
    "#           Component 4: 0.0081 \n",
    "######\n",
    "\n",
    "X_std = df.drop('label', axis=1)\n",
    "\n",
    "# Apply PCA with 4 components\n",
    "pca_model = PCA(n_components=4)\n",
    "X_transformed = pca_model.fit_transform(X_std)\n",
    "\n",
    "pca_dataframe = pd.DataFrame(\n",
    "    data=X_transformed,\n",
    "    columns=['PC1', 'PC2', 'PC3', 'PC4']\n",
    ")\n",
    "\n",
    "pca_dataframe['label'] = true_labels\n",
    "\n",
    "\n",
    "\n",
    "# Graph the variance\n",
    "variance_explained = pca_model.explained_variance_ratio_\n",
    "cumulative_var = np.cumsum(variance_explained)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(1, len(variance_explained) + 1), variance_explained, alpha=0.7, label='Individual variance')\n",
    "plt.step(range(1, len(cumulative_var) + 1), cumulative_var, where='mid', label='Cumulative variance')\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='90% threshold')\n",
    "\n",
    "# Calc how many components needed for 90% variance\n",
    "needed_components = np.argmax(cumulative_var >= 0.9) + 1\n",
    "plt.axvline(x=needed_components, color='g', linestyle='--', \n",
    "            label=f'{needed_components} components needed for 90% variance')\n",
    "\n",
    "plt.xlabel('Principal Components')\n",
    "plt.ylabel('Variance Ratio')\n",
    "plt.title('Variance by Principal Components')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nVariance by component:\")\n",
    "for i, var in enumerate(variance_explained):\n",
    "    print(f\"PC{i+1}: {var:.4f} ({cumulative_var[i]:.4f} cumulative)\")\n",
    "\n",
    "print(f\"\\nNumber of components needed to keep 90% variance: {needed_components}\")\n",
    "\n",
    "# 3d plot of first 3 components\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "unique_labels = np.unique(true_labels)\n",
    "colours = plt.cm.rainbow(np.linspace(0, 1, len(unique_labels)))\n",
    "\n",
    "for label, colour in zip(unique_labels, colours):\n",
    "    mask = pca_dataframe['label'] == label\n",
    "    ax.scatter(\n",
    "        pca_dataframe.loc[mask, 'PC1'],\n",
    "        pca_dataframe.loc[mask, 'PC2'],\n",
    "        pca_dataframe.loc[mask, 'PC3'],\n",
    "        label=label,\n",
    "        color=colour,\n",
    "        alpha=0.7,\n",
    "        s=50\n",
    "    )\n",
    "\n",
    "\n",
    "ax.set_title('First 3 Principal Components')\n",
    "ax.set_xlabel('Component 1')\n",
    "ax.set_ylabel('Component 2')\n",
    "ax.set_zlabel('Component 3')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6 - Investigate DBSCAN Utilising Various Distance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######\n",
    "# Task 6 - Investigate DBSCAN Utilising Various Distance Metrics\n",
    "#\n",
    "# Purpose: To investigate the impact utilising various distance metrics has on the DBSCAN clustering method.\n",
    "# Takeaway: This was an interesting task in that it allowed us to investigate the behaviour of the DBSCAN algorithm.\n",
    "#           DBSCAN is an algorithm were the cluster numbers cannot be predetermined. It also assigns outliers to a cluster label of -1.\n",
    "#            The optimal params for the euclidean distance were eps=0.65, min_samples=5. The optimal params for the mahalanobis distance  were eps=7.00, min_samples=5.\n",
    "#            The euclidean distance had a slightly better mutual information and purity score indicating that it was more aligned to the ground truth labels.\n",
    "#            The silhouette score for mahalanobis distance was higher suggesting that it discovered a more compact cluster structure.\n",
    "#######\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_std = scaler.fit_transform(df[num_cols]) # fit then transform the numerical columns\n",
    "\n",
    "# Calculate purity - how well our clusters match the true labels\n",
    "def calc_purity(true_labels, predicted_labels):\n",
    "    contingency_matrix = np.zeros((len(np.unique(true_labels)), len(np.unique(predicted_labels))))\n",
    "    \n",
    "    for i, true_label in enumerate(np.unique(true_labels)):\n",
    "        for j, pred_label in enumerate(np.unique(predicted_labels)):\n",
    "            contingency_matrix[i, j] = np.sum((true_labels == true_label) & (predicted_labels == pred_label))\n",
    "    \n",
    "    cluster_sizes = np.sum(contingency_matrix, axis=0)\n",
    "    max_correct = np.sum(np.max(contingency_matrix, axis=0))\n",
    "    \n",
    "    purity = max_correct / len(true_labels)\n",
    "    return purity\n",
    "\n",
    "\n",
    "\n",
    "# find the best eps value for euclidean distance\n",
    "def find_best_eps(X, min_samples, target_clusters=2, eps_range=np.arange(0.1, 2.0, 0.05)):\n",
    "    results = []\n",
    "    \n",
    "    for eps in eps_range:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(X)\n",
    "        num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        outliers = np.sum(labels == -1)\n",
    "        \n",
    "        results.append({\n",
    "            'eps': eps,\n",
    "            'num_clusters': num_clusters,\n",
    "            'outliers': outliers,\n",
    "            'labels': labels\n",
    "        })\n",
    "    \n",
    "    return min(results, key=lambda x: abs(x['num_clusters'] - target_clusters))\n",
    "\n",
    "# let's try different min_samples values\n",
    "min_samples_options = [5, 10, 15, 20, 25, 30]\n",
    "euclidean_results = []\n",
    "\n",
    "for min_samples in min_samples_options:\n",
    "    result = find_best_eps(X_std, min_samples)\n",
    "    result['min_samples'] = min_samples\n",
    "    euclidean_results.append(result)\n",
    "    print(f\"Euclidean - min_samples={min_samples}, eps={result['eps']:.2f}, clusters={result['num_clusters']}, outliers={result['outliers']}\")\n",
    "\n",
    "# pick the best eps\n",
    "best_euclidean = min(euclidean_results, key=lambda x: abs(x['num_clusters'] - 2))\n",
    "print(f\"\\nBest Euclidean parameters: eps={best_euclidean['eps']:.2f}, min_samples={best_euclidean['min_samples']}\")\n",
    "\n",
    "# calculate distances for mahalanobis\n",
    "cov = np.cov(X_std.T)\n",
    "inv_cov = np.linalg.inv(cov)\n",
    "\n",
    "def create_mahalanobis_dist_matrix(X, inv_cov):\n",
    "    n = X.shape[0]\n",
    "    dist_matrix = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            dist = mahalanobis(X[i], X[j], inv_cov)\n",
    "            dist_matrix[i, j] = dist\n",
    "            dist_matrix[j, i] = dist\n",
    "    \n",
    "    return dist_matrix\n",
    "\n",
    "# create the Mahalanobis distance matrix\n",
    "mahalanobis_dist_matrix = create_mahalanobis_dist_matrix(X_std, inv_cov)\n",
    "\n",
    "# find the best eps for Mahalanobis distance\n",
    "def find_best_eps_precomputed(dist_matrix, min_samples, target_clusters=2, eps_range=np.arange(0.5, 10.0, 0.5)):\n",
    "    results = []\n",
    "    \n",
    "    for eps in eps_range:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples, metric='precomputed')\n",
    "        labels = dbscan.fit_predict(dist_matrix)\n",
    "        num_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "        outliers = np.sum(labels == -1)\n",
    "        \n",
    "        results.append({\n",
    "            'eps': eps,\n",
    "            'num_clusters': num_clusters,\n",
    "            'outliers': outliers,\n",
    "            'labels': labels\n",
    "        })\n",
    "    \n",
    "    return min(results, key=lambda x: abs(x['num_clusters'] - target_clusters))\n",
    "\n",
    "mahalanobis_results = []\n",
    "\n",
    "for min_samples in min_samples_options:\n",
    "    result = find_best_eps_precomputed(mahalanobis_dist_matrix, min_samples)\n",
    "    result['min_samples'] = min_samples\n",
    "    mahalanobis_results.append(result)\n",
    "    print(f\"Mahalanobis - min_samples={min_samples}, eps={result['eps']:.2f}, clusters={result['num_clusters']}, outliers={result['outliers']}\")\n",
    "\n",
    "# find best parameters for mahalanobis\n",
    "best_mahalanobis = min(mahalanobis_results, key=lambda x: abs(x['num_clusters'] - 2))\n",
    "print(f\"\\nBest Mahalanobis parameters: eps={best_mahalanobis['eps']:.2f}, min_samples={best_mahalanobis['min_samples']}\")\n",
    "\n",
    "# run dbscan with best parameters for euclidean\n",
    "euclidean_dbscan = DBSCAN(eps=best_euclidean['eps'], min_samples=best_euclidean['min_samples'])\n",
    "euclidean_labels = euclidean_dbscan.fit_predict(X_std)\n",
    "\n",
    "# run dbscan with best parameters for mahalanobis\n",
    "mahalanobis_dbscan = DBSCAN(eps=best_mahalanobis['eps'], min_samples=best_mahalanobis['min_samples'], metric='precomputed')\n",
    "mahalanobis_labels = mahalanobis_dbscan.fit_predict(mahalanobis_dist_matrix)\n",
    "\n",
    "# calculate metrics for Euclidean distance\n",
    "euclidean_purity = calc_purity(true_labels, euclidean_labels)\n",
    "euclidean_mi = mutual_info_score(true_labels, euclidean_labels)\n",
    "\n",
    "# filter out noise cluster (-1 label)\n",
    "euclidean_filtered_idx = euclidean_labels != -1\n",
    "euclidean_filtered_labels = euclidean_labels[euclidean_filtered_idx]\n",
    "true_labels_euclidean_filtered = true_labels[euclidean_filtered_idx]\n",
    "\n",
    "# calculate silhouette score\n",
    "if len(set(euclidean_filtered_labels)) > 1:\n",
    "    euclidean_silhouette = silhouette_score(X_std[euclidean_filtered_idx], euclidean_filtered_labels)\n",
    "else:\n",
    "    euclidean_silhouette = \"N/A\"  # Not applicable if only one cluster remains\n",
    "\n",
    "# calculate metrics for Mahalanobis distance\n",
    "mahalanobis_purity = calc_purity(true_labels, mahalanobis_labels)\n",
    "mahalanobis_mi = mutual_info_score(true_labels, mahalanobis_labels)\n",
    "\n",
    "# filter out noise cluster (-1 label)\n",
    "mahalanobis_filtered_idx = mahalanobis_labels != -1\n",
    "mahalanobis_filtered_labels = mahalanobis_labels[mahalanobis_filtered_idx]\n",
    "true_labels_mahalanobis_filtered = true_labels[mahalanobis_filtered_idx]\n",
    "\n",
    "if len(set(mahalanobis_filtered_labels)) > 1:\n",
    "    mahalanobis_silhouette = silhouette_score(X_std[mahalanobis_filtered_idx], mahalanobis_filtered_labels)\n",
    "else:\n",
    "    mahalanobis_silhouette = \"N/A\"  # Not applicable if only one cluster remains\n",
    "\n",
    "euclidean_cluster_count = len(set(euclidean_labels))\n",
    "mahalanobis_cluster_count = len(set(mahalanobis_labels))\n",
    "\n",
    "print(\"\\nMetrics results:\")\n",
    "print(f\"Euclidean - Purity: {euclidean_purity:.4f}, Mutual Information: {euclidean_mi:.4f}, Silhouette: {euclidean_silhouette}, Cluster Count: {euclidean_cluster_count}\")\n",
    "print(f\"Mahalanobis - Purity: {mahalanobis_purity:.4f}, Mutual Information: {mahalanobis_mi:.4f}, Silhouette: {mahalanobis_silhouette}, Cluster Count: {mahalanobis_cluster_count}\")\n",
    "\n",
    "if len(set(euclidean_filtered_labels)) > 1:\n",
    "    euclidean_silhouette = silhouette_score(X_std[euclidean_filtered_idx], euclidean_filtered_labels)\n",
    "else:\n",
    "    euclidean_silhouette = \"N/A\"  # Not applicable if only one cluster remains\n",
    "\n",
    "# calculate metrics for Mahalanobis distance\n",
    "mahalanobis_purity = calc_purity(true_labels, mahalanobis_labels)\n",
    "mahalanobis_mi = mutual_info_score(true_labels, mahalanobis_labels)\n",
    "\n",
    "# filter out noise cluster (-1 label)\n",
    "mahalanobis_filtered_idx = mahalanobis_labels != -1\n",
    "mahalanobis_filtered_labels = mahalanobis_labels[mahalanobis_filtered_idx]\n",
    "true_labels_mahalanobis_filtered = true_labels[mahalanobis_filtered_idx]\n",
    "\n",
    "if len(set(mahalanobis_filtered_labels)) > 1:\n",
    "    mahalanobis_silhouette = silhouette_score(X_std[mahalanobis_filtered_idx], mahalanobis_filtered_labels)\n",
    "else:\n",
    "    mahalanobis_silhouette = \"N/A\"  # Not applicable if only one cluster remains\n",
    "\n",
    "euclidean_cluster_count = len(set(euclidean_labels))\n",
    "mahalanobis_cluster_count = len(set(mahalanobis_labels))\n",
    "\n",
    "print(\"\\nMetrics results:\")\n",
    "print(f\"Euclidean - Purity: {euclidean_purity:.4f}, Mutual Information: {euclidean_mi:.4f}, Silhouette: {euclidean_silhouette}, Cluster Count: {euclidean_cluster_count}\")\n",
    "print(f\"Mahalanobis - Purity: {mahalanobis_purity:.4f}, Mutual Information: {mahalanobis_mi:.4f}, Silhouette: {mahalanobis_silhouette}, Cluster Count: {mahalanobis_cluster_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7 - Comparative Performance of Original vs Dimensionality Reduced Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 7 - Comparative Performance of Original vs Dimensionality Reduced Datasets\n",
    "#\n",
    "# Purpose: Compare the performance of the original and PCA-transformed datasets using KMeans clustering.\n",
    "# Takeaway: After KMeans clustering was performed on the original and PCA-transformed datasets, the results were:\n",
    "#           PCA: Silhouette=0.484\n",
    "#           Original: Silhouette=0.441  \n",
    "#           The Principal Component Analysis dataset produced a higher silhouette score via KMeans clustering, suggesting that it has discovered a better defined cluster structure.\n",
    "#########\n",
    "\n",
    "X_pca = pca_dataframe.drop(columns='label', axis=1)\n",
    "\n",
    "# function to run kmeans and eval silhouette and inertia score\n",
    "def run_kmeans_and_check_quality(data_points, dataset_name, n_clusters_range=range(2, 11)):\n",
    "    findings = []\n",
    "    \n",
    "    for k in n_clusters_range:\n",
    "        # Apply KMeans\n",
    "        kmeans_algo = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "        kmeans_groupings = kmeans_algo.fit_predict(data_points)\n",
    "        \n",
    "        # Calculate silhouette score\n",
    "        silhouette_val = silhouette_score(data_points, kmeans_groupings)\n",
    "        \n",
    "        # Calculate inertia (sum of squared distances to closest centroid)\n",
    "        wobbliness = kmeans_algo.inertia_\n",
    "        \n",
    "        findings.append({\n",
    "            'k': k,\n",
    "            'silhouette': silhouette_val,\n",
    "            'inertia': wobbliness,\n",
    "            'labels': kmeans_groupings\n",
    "        })\n",
    "        \n",
    "        print(f\"{dataset_name} with {k} clusters - Silhouette Score: {silhouette_val:.3f}, Inertia: {wobbliness:.2f}\")\n",
    "    \n",
    "    return findings\n",
    "\n",
    "# original dataset\n",
    "raw_data_results = run_kmeans_and_check_quality(X_std, \"Original Dataset\")\n",
    "\n",
    "# pca dataset\n",
    "pca_data_results = run_kmeans_and_check_quality(X_pca, \"PCA Dataset\")\n",
    "\n",
    "# Plot results\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot([r['k'] for r in raw_data_results], [r['silhouette'] for r in raw_data_results], 'o-', label='Original Dataset')\n",
    "plt.plot([r['k'] for r in pca_data_results], [r['silhouette'] for r in pca_data_results], 'o-', label='PCA Dataset')\n",
    "plt.xlabel('Number of Clusters (k)')\n",
    "plt.ylabel('Silhouette')\n",
    "plt.title('Silhouette vs. Cluster Number')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "# find the best on silhouette score\n",
    "best_k_raw = max(raw_data_results, key=lambda x: x['silhouette'])\n",
    "best_k_pca = max(pca_data_results, key=lambda x: x['silhouette'])\n",
    "\n",
    "print(\"\\nBest results:\")\n",
    "print(f\"Original Dataset: k={best_k_raw['k']}, Silhouette Score={best_k_raw['silhouette']:.3f}\")\n",
    "print(f\"PCA Dataset: k={best_k_pca['k']}, Silhouette Score={best_k_pca['silhouette']:.3f}\")\n",
    "\n",
    "# determine which is better\n",
    "if best_k_pca['silhouette'] > best_k_raw['silhouette']:\n",
    "    print(\"\\nPCA dataset is better, innit.\")\n",
    "else:\n",
    "    print(\"\\nOriginal dataset is better, mate.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8 - Dimensionality Reduction Using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 8 - Clustering Using t-SNE\n",
    "#\n",
    "# Purpose: Create a new dataset with only 4 features using t-SNE, then compare its performance using KMeans clustering.\n",
    "# Takeaway: A new dataset was created with only 4 features using t-SNE. After Kmeans clustering was performed, the dataset performance was::\n",
    "#           t-SNE Dataset: Silhouette=0.400\n",
    "#           Original Dataset:  Silhouette=0.441\n",
    "#           PCA Dataset: Silhouette=0.484\n",
    "#           The t-SNA dataset had the lowest silhouette score suggesting that Kmeans clustering couldnt find a good cluster structure.\n",
    "#########\n",
    "\n",
    "\n",
    "# compute t-SNE \n",
    "t_sne = TSNE(n_components=4, method='exact', random_state=42)\n",
    "X_t_sne = t_sne.fit_transform(X_std)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "if 'label' in df.columns:\n",
    "    labels = df['label'].unique()\n",
    "    for i, label in enumerate(labels):\n",
    "        indices = df['label'] == label\n",
    "        ax.scatter(X_t_sne[indices, 0], X_t_sne[indices, 1], X_t_sne[indices, 2], \n",
    "                   label=label, alpha=0.7)\n",
    "else:\n",
    "    ax.scatter(X_t_sne[:, 0], X_t_sne[:, 1], X_t_sne[:, 2], alpha=0.7)\n",
    "\n",
    "ax.set_title('3D t-SNE Visualisation')\n",
    "ax.set_xlabel('Comp. 1')\n",
    "ax.set_ylabel('Comp. 2')\n",
    "ax.set_zlabel('Comp. 3')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "distortions_list = []\n",
    "silhouette_vals = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans_model.fit(X_t_sne)\n",
    "    distortions_list.append(kmeans_model.inertia_)\n",
    "    \n",
    "    kmeans_cluster_labels = kmeans_model.labels_\n",
    "    silhouette_avg = silhouette_score(X_t_sne, kmeans_cluster_labels)\n",
    "    silhouette_vals.append(silhouette_avg)\n",
    "\n",
    "\n",
    "# calc scores\n",
    "t_sne_results = []\n",
    "for k in K_range:\n",
    "    kmeans_model = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    tsne_cluster_labels = kmeans_model.fit_predict(X_t_sne)\n",
    "    tsne_silhouette_avg = silhouette_score(X_t_sne, tsne_cluster_labels)\n",
    "    t_sne_results.append({'k': k, 'silhouette': tsne_silhouette_avg})\n",
    "\n",
    "best_k_t_sne = max(t_sne_results, key=lambda x: x['silhouette'])\n",
    "\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(f\"Original Dataset: k={best_k_raw['k']}, Silhouette Score={best_k_raw['silhouette']:.3f}\")\n",
    "print(f\"PCA Dataset: k={best_k_pca['k']}, Silhouette Score={best_k_pca['silhouette']:.3f}\")\n",
    "print(f\"t-SNE Dataset: k={best_k_t_sne['k']}, Silhouette Score={best_k_t_sne['silhouette']:.3f}\")\n",
    "\n",
    "# find the best\n",
    "best_method = max([\n",
    "    ('Original', best_k_raw['silhouette']),\n",
    "    ('PCA', best_k_pca['silhouette']),\n",
    "    ('t-SNE', best_k_t_sne['silhouette'])\n",
    "], key=lambda x: x[1])\n",
    "\n",
    "print(f\"\\nThe {best_method[0]} dataset provides better clustering quality with a silhouette score of {best_method[1]:.3f}, innit.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
