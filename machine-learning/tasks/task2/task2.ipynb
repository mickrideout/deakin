{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import hashlib\n",
    "import random\n",
    "from tabulate import tabulate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "# Set the random seed so reruns are deterministic\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 1\n",
    "#########\n",
    "def generate_sensor_id():\n",
    "    \"\"\"\n",
    "      Generate a hashed, unique and random sensor id string\n",
    "    \"\"\"\n",
    "    id_to_hash = f\"Sensor_id_{random.random()}\"\n",
    "    id_hashed = hashlib.sha256(id_to_hash.encode())\n",
    "    return id_hashed.hexdigest()\n",
    "\n",
    "def sensor_id_valid(sensor_id, all_sensor_ids):\n",
    "    \"\"\"\n",
    "      A sensor id is valid if it is unique in all sensor ids (ie its can only be counted once)\n",
    "    \"\"\"\n",
    "    if all_sensor_ids.count(sensor_id) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def temperature_reading_valid(temperature_reading):\n",
    "    \"\"\"\n",
    "      Validate the temperature reading is between -10 and 50\n",
    "    \"\"\"\n",
    "    if temperature_reading >= -10 and temperature_reading <= 50:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def humidity_level_valid(humidity_level):\n",
    "    \"\"\"\n",
    "      Validate that the humidity level is between 10% and 100%\n",
    "    \"\"\"\n",
    "    if humidity_level >= 10 and humidity_level <= 100:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# Arrays to hold sensor data\n",
    "Sensor_IDs = []\n",
    "Temperature_Readings = []\n",
    "Humidity_Levels = []\n",
    "\n",
    "# Generate 5 random sensor ids, temperature readings and humidity levels\n",
    "for i in range(5):\n",
    "    Sensor_IDs.append(generate_sensor_id())\n",
    "    Temperature_Readings.append(random.randint(-10, 50))\n",
    "    Humidity_Levels.append(random.randint(10, 100))\n",
    "\n",
    "# Validate and print all data\n",
    "for i in range(5):\n",
    "    sensor_id = Sensor_IDs[i]\n",
    "    temperature_reading = Temperature_Readings[i]\n",
    "    humidity_level = Humidity_Levels[i]\n",
    "    print(f\"Sensor_id={sensor_id}, temperature_reading={temperature_reading}, humidity_level={humidity_level}\")\n",
    "    all_data_valid = True\n",
    "    if not sensor_id_valid(sensor_id, Sensor_IDs):\n",
    "        print(\"Sensor_id is not unique\")\n",
    "        all_data_valid = False\n",
    "    if not temperature_reading_valid(temperature_reading):\n",
    "        print(\"Temperature reading is invalid\")\n",
    "        all_data_valid = False\n",
    "    if not humidity_level_valid(humidity_level):\n",
    "        print(\"Humidity level not valid\")\n",
    "        all_data_valid = False\n",
    "\n",
    "    if all_data_valid:\n",
    "        print(\"All entries are valid\")\n",
    "    print (\"---------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 2\n",
    "#########\n",
    "\n",
    "\n",
    "def create_sensor_data_dict(sensor_ids, temperature_readings, humidity_levels):\n",
    "    \"\"\"\n",
    "      Create a dictionary from sensor data. Throws exception if data is any data points are invalid\n",
    "    \"\"\"\n",
    "    sensor_data = {}\n",
    "    for sensor_id, temp, humidity in zip(sensor_ids, temperature_readings, humidity_levels):\n",
    "        if sensor_id and temperature_reading_valid(temp) and humidity_level_valid(humidity):\n",
    "            sensor_data[sensor_id] = {\n",
    "                'Temperature_Reading': temp,\n",
    "                'Humidity_Level': humidity\n",
    "            }\n",
    "        else:\n",
    "            raise Exception(\"Invalid sensor data: sensor_id, temperature_reading, or humidity_level is invalid.\")\n",
    "    return sensor_data\n",
    "\n",
    "def filter_and_sort_sensors(sensor_data, temp_threshold):\n",
    "    \"\"\"\n",
    "      Filters data exceeding temp_threshold, sorts by temperature descending and prints top three readings\n",
    "    \"\"\"\n",
    "    filtered_sensors = {k: v for k, v in sensor_data.items() if v['Temperature_Reading'] > temp_threshold}\n",
    "    sorted_sensors = dict(sorted(filtered_sensors.items(), key=lambda item: item[1]['Temperature_Reading'], reverse=True))\n",
    "    \n",
    "    top_3 = list(sorted_sensors.items())[:3]\n",
    "    for sensor_id, data in top_3:\n",
    "        print(f\"Sensor_ID: {sensor_id}, Temperature: {data['Temperature_Reading']}, Humidity: {data['Humidity_Level']}\")\n",
    "\n",
    "\n",
    "print(\"Sensor data where temperature is greater than 0\")\n",
    "sensor_dict = create_sensor_data_dict(Sensor_IDs, Temperature_Readings, Humidity_Levels)\n",
    "filter_and_sort_sensors(sensor_dict, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 3\n",
    "#########\n",
    "\n",
    "air_quality = None\n",
    "GOOD = 'Good'\n",
    "MODERATE = 'Moderate'   \n",
    "UNHEALTHY = 'Unhealthy'\n",
    "HAZARDOUS = 'Hazardous'\n",
    "air_quality_categories = [GOOD, MODERATE, UNHEALTHY, HAZARDOUS]\n",
    "\n",
    "def recommend_activity(air_quality):\n",
    "    activities = {\n",
    "        GOOD: ['hiking', 'biking', 'swimming'],\n",
    "        MODERATE: ['walking', 'cycling', 'jogging'],\n",
    "        UNHEALTHY: ['watch movie', 'cooking', 'board games'],\n",
    "        HAZARDOUS: ['stay indoors', 'visit shopping centre']\n",
    "    }\n",
    "    return random.choice(activities.get(air_quality, [\"Invalid air quality\"]))\n",
    "\n",
    "def get_air_quality():\n",
    "    while True:\n",
    "        air_quality = input(\"Enter air quality (Good, Moderate, Unhealthy, Hazardous): \")\n",
    "        if air_quality in air_quality_categories:\n",
    "            return air_quality\n",
    "        else:\n",
    "            print(\"Invalid input. Please enter a valid air quality.\")\n",
    "\n",
    "def simulate_air_quality_readings():\n",
    "    readings = [random.choice(air_quality_categories) for _ in range(10)]\n",
    "    counts = {category: readings.count(category) for category in air_quality_categories}\n",
    "    percentages = {category: (count / len(readings)) * 100 for category, count in counts.items()}\n",
    "    return counts, percentages\n",
    "\n",
    "def print_results(counts, percentages):\n",
    "    results = [[category, counts[category], f\"{percentages[category]:.2f}%\"] for category in air_quality_categories]\n",
    "    print(tabulate(results, headers=['Air Quality', 'Count', 'Percentage'], tablefmt='orgtbl'))\n",
    "\n",
    "\n",
    "print(\"\\nSimulated Air Quality Readings:\")\n",
    "counts, percentages = simulate_air_quality_readings()\n",
    "print_results(counts, percentages)\n",
    "\n",
    "print(\"\\nGet Air Quality Recommendation:\")\n",
    "air_quality_input = get_air_quality()\n",
    "print(f\"Recommended activity: {recommend_activity(air_quality_input)}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 4\n",
    "#########\n",
    "\n",
    "even_numbers = []\n",
    "odd_numbers = []\n",
    "seen_numbers = set()\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        num = int(input(\"Enter a number (negative number to stop): \"))\n",
    "        \n",
    "        if num < 0:\n",
    "            break\n",
    "        \n",
    "        if num in seen_numbers:\n",
    "            print(\"You've already entered this number. Try a different one.\")\n",
    "            continue\n",
    "        \n",
    "        seen_numbers.add(num)\n",
    "        \n",
    "        if num % 2 == 0:\n",
    "            even_numbers.append(num)\n",
    "        else:\n",
    "            odd_numbers.append(num)\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Invalid input. Please enter a valid number.\")\n",
    "\n",
    "with open(\"loop_log.txt\", \"w\") as file:\n",
    "    file.write(f\"Even numbers: {even_numbers}\\n\")\n",
    "    file.write(f\"Odd numbers: {odd_numbers}\\n\")\n",
    "\n",
    "print(\"Numbers have been logged in 'loop_log.txt'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 5\n",
    "#########\n",
    "\n",
    "def print_character_positions(term):\n",
    "    even_positions = \"\"\n",
    "    odd_positions = \"\"\n",
    "    for i in range(len(term)):\n",
    "        if i % 2 == 0:\n",
    "            even_positions += term[i]\n",
    "            odd_positions += \" \"\n",
    "        else:\n",
    "            odd_positions += term[i]\n",
    "            even_positions += \" \"\n",
    "    print(\"Characters at even positions: \", even_positions)\n",
    "    print(\"Characters at  odd positions: \", odd_positions)\n",
    "\n",
    "term = input(\"Enter a scientific term: \")\n",
    "print_character_positions(term)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 6\n",
    "#########\n",
    "\n",
    "WIND_SPEED_COLUMN = 'Wind_Speed_kmh'\n",
    "\n",
    "weather_data = pd.read_csv('WeatherData.csv')\n",
    "\n",
    "# There is a superfluous unnamed column, so we drop it\n",
    "weather_data.drop(columns=['Unnamed: 6'], inplace=True)\n",
    "\n",
    "# Display row and columns counts\n",
    "print(f\"Number of weather stations: {weather_data.shape[0]}\")\n",
    "print(f\"Number of recorded parameters: {weather_data.shape[1]}\")\n",
    "\n",
    "# mean wind speed\n",
    "mean_wind_speed = weather_data[WIND_SPEED_COLUMN].mean()\n",
    "\n",
    "# modify wind speed\n",
    "weather_data['Modified Wind Speed'] = weather_data[WIND_SPEED_COLUMN] - mean_wind_speed\n",
    "\n",
    "# Print both the original and modified values\n",
    "print(\"Original Wind Speed Values:\")\n",
    "print(weather_data[WIND_SPEED_COLUMN])\n",
    "print(\"\\nModified Wind Speed Values:\")\n",
    "print(weather_data['Modified Wind Speed'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 7\n",
    "#########\n",
    "\n",
    "\n",
    "weather_data = pd.read_csv('WeatherData.csv')\n",
    "\n",
    "# There is a superfluous unnamed column, so we drop it\n",
    "weather_data.drop(columns=['Unnamed: 6'], inplace=True)\n",
    "\n",
    "print(\"Dataset Information:\")\n",
    "print(weather_data.info())\n",
    "\n",
    "# Investigate missing values\n",
    "print(\"\\nMissing Values Count:\")\n",
    "missing_values = weather_data.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "# Identify numeric and categorical columns\n",
    "numeric_columns = ['Temperature_C', 'Humidity_%', 'Wind_Speed_kmh', 'Precipitation_mm']\n",
    "\n",
    "# Make copies for different imputation methods\n",
    "weather_data_median = weather_data.copy()\n",
    "weather_data_mode = weather_data.copy()\n",
    "\n",
    "###\n",
    "# Justification for imputation techniques\n",
    "#\n",
    "# For the numeric columns, we used median imputation because it is robust to outliers and preserves the overall distribution.\n",
    "# For the categorical columns, we used mode imputation because it is a simple and effective way to impute missing values.\n",
    "###\n",
    "\n",
    "# Justification for imputation techniques\n",
    "print(\"\\nJustification for Imputation Techniques:\")\n",
    "print(\"1. Median Imputation: Median imputation is robust to outliers and preserves the overall distribution.\")\n",
    "print(\"2. Mode Imputation: We used mode imputation because it is a simple and effective way to impute missing values.\")\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Create plots\n",
    "for i, column in enumerate(numeric_columns):\n",
    "    if missing_values[column] > 0:\n",
    "        # This column has missing values\n",
    "\n",
    "        # Original data distribution\n",
    "        plt.subplot(4, 3, 3*i+1)\n",
    "        sns.histplot(weather_data[column].dropna(), kde=True)\n",
    "        plt.title(f'Original {column} Distribution')\n",
    "        \n",
    "        # Technique 1: Median Imputation \n",
    "        median_imputer = SimpleImputer(strategy='median')\n",
    "        weather_data_median[column] = median_imputer.fit_transform(weather_data_median[[column]])\n",
    "        \n",
    "        plt.subplot(4, 3, 3*i+2)\n",
    "        sns.histplot(weather_data_median[column], kde=True)\n",
    "        plt.title(f'{column} with Median Imputation Distribution')\n",
    "        \n",
    "        # Technique 2: Mode Imputation\n",
    "        mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        weather_data_mode[column] = mode_imputer.fit_transform(weather_data_mode[[column]])\n",
    "        \n",
    "        plt.subplot(4, 3, 3*i+3)\n",
    "        sns.histplot(weather_data_mode[column], kde=True)\n",
    "        plt.title(f'{column} with Mode Imputation Distribution')\n",
    "        \n",
    "        print(f\"\\nImputation for {column}:\")\n",
    "        print(f\"Number of missing values: {missing_values[column]}\")\n",
    "        print(f\"Median value used for imputation: {weather_data[column].median()}\")\n",
    "        print(f\"Mode value used for imputation: {weather_data[column].mode()[0]}\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Distribution comparison\n",
    "\n",
    "print(\"\\nDistribution Comparison:\")\n",
    "print(\"1. Temperature_C: The original distribution has a more normal distribution, while the median and mode imputed distributions have a distribution with a spike at the median value.\")\n",
    "print(\"2. Humidity_%: The original and median imputed distributions are similar, but the mode imputed distribution has a spike at the mode value.\")\n",
    "\n",
    "\n",
    "# Save the median imputed dataset\n",
    "weather_data_median.to_csv('WeatherData_Cleaned.csv', index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 8\n",
    "#########\n",
    "\n",
    "# Perform one-hot encoding on the Weather_Condition column\n",
    "encoded_weather = pd.get_dummies(weather_data['Weather_Condition'], prefix='Weather')\n",
    "print(\"\\nEncoded weather conditions:\")\n",
    "print(encoded_weather.head())\n",
    "\n",
    "weather_data_encoded = weather_data.copy()\n",
    "weather_data_encoded = pd.concat([weather_data_encoded, encoded_weather], axis=1)\n",
    "\n",
    "# Drop the original Weather_Condition column\n",
    "weather_data_encoded = weather_data_encoded.drop('Weather_Condition', axis=1)\n",
    "\n",
    "print(\"\\nDataset with encoded weather conditions:\")\n",
    "print(weather_data_encoded.head())\n",
    "\n",
    "print(\"\\nJustification for using one-hot encoding:\")\n",
    "print(\"1. Weather condition (Sunny, Rainy, Cloudy, Stormy) is categorical and has no natural ordering so one-hot encoding allows each weather condition to have an independent effect on the model.\")\n",
    "print(\"2. As there are only 4 categories, the dimensionality increase is manageable\")\n",
    "\n",
    "weather_data_encoded.to_csv('WeatherData_Encoded.csv', index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########\n",
    "# Task 9\n",
    "#########\n",
    "\n",
    "weather_data_scaled = weather_data_encoded.copy()\n",
    "numerical_cols = ['Temperature_C', 'Humidity_%', 'Wind_Speed_kmh', 'Precipitation_mm']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Apply Min-Max scaling to the numerical columns\n",
    "weather_data_scaled[numerical_cols] = scaler.fit_transform(weather_data_scaled[numerical_cols])\n",
    "\n",
    "print(\"\\nDataset after Min-Max scaling:\")\n",
    "print(weather_data_scaled.head())\n",
    "\n",
    "plt.figure(figsize=(15, 12))\n",
    "\n",
    "# Histogram of temperatures before and after scaling\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.hist(weather_data_encoded['Temperature_C'], bins=15, alpha=0.7, color='blue')\n",
    "plt.title('Temperature Distribution Before Scaling')\n",
    "plt.xlabel('Temperature (°C)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(weather_data_scaled['Temperature_C'], bins=15, alpha=0.7, color='green')\n",
    "plt.title('Temperature Distribution After Min-Max Scaling')\n",
    "plt.xlabel('Scaled Temperature (0-1)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Boxplot of wind speed before and after scaling\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.boxplot(weather_data_encoded['Wind_Speed_kmh'])\n",
    "plt.title('Wind Speed Distribution Before Scaling')\n",
    "plt.ylabel('Wind Speed (km/h)')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.boxplot(weather_data_scaled['Wind_Speed_kmh'])\n",
    "plt.title('Wind Speed Distribution After Min-Max Scaling')\n",
    "plt.ylabel('Scaled Wind Speed (0-1)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analysis\n",
    "print(\"\\nAnalysis of Min-Max Scaling Effects:\")\n",
    "print(\"1. Range Transformation: All numerical features now have the same range, making them comparable. That is, the minimum value is 0 and the maximum value is 1.\")\n",
    "print(\"2. Distribution Preservation: There is no change to the shape of the distribution.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
