{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating Algorithms for Imbalanced Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Student Name: Michael Rideout\n",
    "* Student Number: 225065259\n",
    "* E-mail: s225065259@deakin.edu.au\n",
    "* Student Course Code: SIT731\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imblearn in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (0.0)\n",
      "Requirement already satisfied: imbalanced-learn in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from imblearn) (0.13.0)\n",
      "Requirement already satisfied: numpy<3,>=1.24.3 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.26.4)\n",
      "Requirement already satisfied: scipy<2,>=1.10.1 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.14.1)\n",
      "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.5.1)\n",
      "Requirement already satisfied: sklearn-compat<1,>=0.1 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (0.1.3)\n",
      "Requirement already satisfied: joblib<2,>=1.1.1 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from imbalanced-learn->imblearn) (3.5.0)\n",
      "Requirement already satisfied: river in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (0.22.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from river) (1.26.4)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.2.3 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from river) (2.2.3)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.14.1 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from river) (1.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from pandas<3.0.0,>=2.2.3->river) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from pandas<3.0.0,>=2.2.3->river) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from pandas<3.0.0,>=2.2.3->river) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/mick/bin/anaconda/envs/scratch/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.2.3->river) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import compute_sample_weight\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "\n",
    "!pip install imblearn\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "\n",
    "!pip install river\n",
    "from river import datasets\n",
    "from river import evaluate\n",
    "from river import metrics\n",
    "from river import preprocessing\n",
    "from river import compose\n",
    "from river import tree, ensemble, forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "- Generate synthetic datasets\n",
    "- Test algorithms for imbalanced data\n",
    "- Evaluate performance\n",
    "- Report Findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Synthetic datasets\n",
    "- Create datasets with varying class imbalance ratios (5, 10, 20, 50, 100) based on the size of the majority class relative to the minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyntheticDatasetGenerator():\n",
    "\n",
    "    def generate_dataset(self, row_count, imbalance_ratio):\n",
    "        majority_class_weight = imbalance_ratio / (imbalance_ratio + 1)\n",
    "        minority_class_weight = 1 / (imbalance_ratio + 1)\n",
    "        X, y = make_classification(n_samples=row_count, n_features=20, random_state=42, weights=[minority_class_weight, majority_class_weight])\n",
    "\n",
    "        # Create a DataFrame\n",
    "        df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(X.shape[1])]) \n",
    "        df['label'] = y\n",
    "        return df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    9848\n",
       "0     152\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syn = SyntheticDatasetGenerator()\n",
    "df = syn.generate_dataset(10000, 100)\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define constants\n",
    "\n",
    "\n",
    "class BaseClassifier:\n",
    "\n",
    "    def __init__(self, algorithm_name, target_column_name) -> None:\n",
    "        self.algorithm_name = algorithm_name\n",
    "        self.target_column_name = target_column_name\n",
    "\n",
    "    \n",
    "    def fit(self, full_dataset: pd.DataFrame, train_data: pd.DataFrame):\n",
    "        pass\n",
    "\n",
    "    def predict(self, test_data: pd.DataFrame):\n",
    "        pass\n",
    "\n",
    "    def calculate_g_mean(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the geometric mean for evaluating classifier performance.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        y_true : array-like\n",
    "            Ground truth (correct) labels\n",
    "        y_pred : array-like\n",
    "            Predicted labels, as returned by a classifier\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            G-mean score ranging from 0 to 1\n",
    "        \"\"\"\n",
    "        # Ensure inputs are numpy arrays\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_pred = np.asarray(y_pred)\n",
    "        \n",
    "        # Calculate the number of positive and negative samples\n",
    "        num_positives = np.sum(y_true)\n",
    "        num_negatives = len(y_true) - num_positives\n",
    "        \n",
    "        # Calculate the number of true positives, true negatives, false positives, and false negatives\n",
    "        true_positives = np.sum(np.logical_and(y_true == 1, y_pred == 1))\n",
    "        true_negatives = np.sum(np.logical_and(y_true == 0, y_pred == 0))\n",
    "        false_positives = np.sum(np.logical_and(y_true == 0, y_pred == 1))\n",
    "        false_negatives = np.sum(np.logical_and(y_true == 1, y_pred == 0))\n",
    "        \n",
    "        # Calculate the sensitivity (true positive rate) and specificity (true negative rate)\n",
    "        sensitivity = true_positives / num_positives\n",
    "        specificity = true_negatives / num_negatives\n",
    "        \n",
    "        # Calculate the g-mean using the sensitivity and specificity\n",
    "        g_mean = np.sqrt(sensitivity * specificity)\n",
    "        \n",
    "        return g_mean\n",
    "\n",
    "    def calculate_auc(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the AUC (Area Under the Curve) for evaluating classifier performance.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        y_true : array-like\n",
    "            Ground truth (correct) labels\n",
    "        y_pred : array-like\n",
    "            Predicted probabilities or scores, as returned by a classifier\n",
    "                \n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            AUC score ranging from 0 to 1\n",
    "        \"\"\"\n",
    "        return roc_auc_score(y_true, y_pred)\n",
    "\n",
    "\n",
    "    def calculate_kappa(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calculate the Cohen's kappa coefficient for evaluating classifier performance.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        y_true : array-like\n",
    "            Ground truth (correct) labels\n",
    "        y_pred : array-like\n",
    "            Predicted labels, as returned by a classifier\n",
    "            \n",
    "        Returns:\n",
    "        --------\n",
    "        float\n",
    "            Kappa coefficient ranging from -1 to 1\n",
    "        \"\"\"\n",
    "        # Ensure inputs are numpy arrays\n",
    "        y_true = np.asarray(y_true)\n",
    "        y_pred = np.asarray(y_pred)\n",
    "        \n",
    "        # Calculate the confusion matrix\n",
    "        confusion = confusion_matrix(y_true, y_pred)\n",
    "        \n",
    "        # Calculate the observed agreement\n",
    "        observed_agreement = np.trace(confusion) / np.sum(confusion)\n",
    "        \n",
    "        # Calculate the expected agreement\n",
    "        expected_agreement = np.sum(np.sum(confusion, axis=0) * np.sum(confusion, axis=1)) / np.sum(confusion)**2\n",
    "        \n",
    "        # Calculate the kappa coefficient\n",
    "        kappa = (observed_agreement - expected_agreement) / (1 - expected_agreement)\n",
    "        \n",
    "        return kappa * 100\n",
    "\n",
    "    \n",
    "    def evaluate(self, dataset: pd.DataFrame):\n",
    "        # split the dataset\n",
    "        train_data, test_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "        self.fit(dataset, train_data)\n",
    "        y_true = test_data[self.target_column_name]\n",
    "        y_pred = self.predict(test_data)\n",
    "        kappa = self.calculate_kappa(y_true, y_pred)\n",
    "        auc = self.calculate_auc(y_true, y_pred)\n",
    "        gmean = self.calculate_g_mean(y_true, y_pred)\n",
    "        print(f\"Model: {self.algorithm_name} \\t AUC: {auc:.2f} Kappa:{kappa:.2f} g-mean: {gmean:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BalancedRandomForestClassifierWrapper(BaseClassifier):\n",
    "\n",
    "    def __init__(self, algorithm_name, target_column_name) -> None:\n",
    "        super().__init__(algorithm_name, target_column_name)\n",
    "        self.clf = BalancedRandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    def fit(self, full_dataset: pd.DataFrame, train_data: pd.DataFrame):\n",
    "        train_df = train_data\n",
    "        x_train = train_df.drop(columns=[self.target_column_name])\n",
    "        y_train = train_df[self.target_column_name]\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, test_data: pd.DataFrame):\n",
    "        return self.clf.predict(test_data.drop(columns=[self.target_column_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARFWrapper(BaseClassifier):\n",
    "    def __init__(self, algorithm_name, target_column_name) -> None:\n",
    "        super().__init__(algorithm_name, target_column_name)\n",
    "        self.clf = forest.ARFClassifier(n_models=10)\n",
    "\n",
    "    def fit(self, full_dataset: pd.DataFrame, train_data: pd.DataFrame):\n",
    "        train_df = train_data\n",
    "        x_train = train_df.drop(columns=[self.target_column_name])\n",
    "        y_train = train_df[self.target_column_name]\n",
    "        self.clf = self.clf.learn_one(x_train, y_train)\n",
    "\n",
    "    def predict(self, test_data: pd.DataFrame):\n",
    "        test_df = test_data.drop(columns=[self.target_column_name])\n",
    "        return test_df.apply(lambda x: self.clf.predict_one(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all train and test datasets ratios 5, 10, 20, 50, 100\n",
    "\n",
    "TARGET_COLUMN_NAME = \"label\"\n",
    "\n",
    "synth_generator = SyntheticDatasetGenerator()\n",
    "\n",
    "TOTAL_ROWS = 10000\n",
    "\n",
    "datasets = {}\n",
    "for ratio in [5, 10, 20, 50, 100]:\n",
    "    datasets[ratio] = synth_generator.generate_dataset(TOTAL_ROWS, ratio)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running ratio 5\n",
      "Model: BRFC \t AUC: 0.92 Kappa:80.66 g-mean: 0.92\n",
      "Running ratio 10\n",
      "Model: BRFC \t AUC: 0.91 Kappa:71.77 g-mean: 0.91\n",
      "Running ratio 20\n",
      "Model: BRFC \t AUC: 0.90 Kappa:57.12 g-mean: 0.90\n",
      "Running ratio 50\n",
      "Model: BRFC \t AUC: 0.86 Kappa:31.05 g-mean: 0.86\n",
      "Running ratio 100\n",
      "Model: BRFC \t AUC: 0.77 Kappa:13.61 g-mean: 0.76\n",
      "Running ratio 5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ratio, dataset \u001b[38;5;129;01min\u001b[39;00m datasets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning ratio \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mratio\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mclassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 113\u001b[0m, in \u001b[0;36mBaseClassifier.evaluate\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: pd\u001b[38;5;241m.\u001b[39mDataFrame):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;66;03m# split the dataset\u001b[39;00m\n\u001b[1;32m    112\u001b[0m     train_data, test_data \u001b[38;5;241m=\u001b[39m train_test_split(dataset, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m test_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_column_name]\n\u001b[1;32m    115\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(test_data)\n",
      "Cell \u001b[0;32mIn[27], line 10\u001b[0m, in \u001b[0;36mARFWrapper.fit\u001b[0;34m(self, full_dataset, train_data)\u001b[0m\n\u001b[1;32m      8\u001b[0m x_train \u001b[38;5;241m=\u001b[39m train_df\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_column_name])\n\u001b[1;32m      9\u001b[0m y_train \u001b[38;5;241m=\u001b[39m train_df[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_column_name]\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bin/anaconda/envs/scratch/lib/python3.12/site-packages/river/forest/adaptive_random_forest.py:161\u001b[0m, in \u001b[0;36mBaseForest.learn_one\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    158\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_one(x)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;66;03m# Update performance evaluator\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_metrics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mClassificationMetric\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_labels\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m k \u001b[38;5;241m=\u001b[39m poisson(rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_value, rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng)\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/bin/anaconda/envs/scratch/lib/python3.12/site-packages/river/metrics/base.py:93\u001b[0m, in \u001b[0;36mClassificationMetric.update\u001b[0;34m(self, y_true, y_pred, w)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_true, y_pred, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bin/anaconda/envs/scratch/lib/python3.12/site-packages/river/metrics/confusion.py:67\u001b[0m, in \u001b[0;36mConfusionMatrix.update\u001b[0;34m(self, y_true, y_pred, w)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_true, y_pred, w\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m):\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bin/anaconda/envs/scratch/lib/python3.12/site-packages/river/metrics/confusion.py:75\u001b[0m, in \u001b[0;36mConfusionMatrix._update\u001b[0;34m(self, y_true, y_pred, w)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, y_true, y_pred, w):\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m]\u001b[49m[y_pred] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m w\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_weight \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m w\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_row[y_true] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m w\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'"
     ]
    }
   ],
   "source": [
    "# Run Classifiers\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    BalancedRandomForestClassifierWrapper(\"BRFC\", TARGET_COLUMN_NAME),\n",
    "    ARFWrapper(\"ARF\", TARGET_COLUMN_NAME)\n",
    "\n",
    "]\n",
    "\n",
    "for classifier in classifiers:\n",
    "    for ratio, dataset in datasets.items():\n",
    "        print (f\"Running ratio {ratio}\")\n",
    "        classifier.evaluate(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
      "0  -0.669356  -1.495778  -0.870766   1.141831   0.021606   1.730630   \n",
      "1   0.093372   0.785848   0.105754   1.272354  -0.846316  -0.979093   \n",
      "2  -0.905797  -0.608341   0.295141   0.943716   0.092936   1.370397   \n",
      "3  -0.585793   0.389279   0.698816   0.436236  -0.315082   0.459505   \n",
      "4   1.146441   0.515579  -1.222895  -0.396230  -1.293508  -0.352428   \n",
      "\n",
      "   feature_7  feature_8  feature_9  feature_10  ...  feature_12  feature_13  \\\n",
      "0  -1.251698   0.289305   0.357163   -0.196811  ...    0.154850   -0.219970   \n",
      "1   1.263707   0.264020   2.411677   -0.960046  ...    0.199810    0.288724   \n",
      "2  -0.064772   0.287273  -0.533004   -0.032504  ...   -0.510064   -0.868768   \n",
      "3   1.448820   0.505558  -1.440982   -1.134020  ...    1.466783    0.678728   \n",
      "4   0.071254   1.239584   1.007133   -1.479444  ...   -0.918127    0.604121   \n",
      "\n",
      "   feature_14  feature_15  feature_16  feature_17  feature_18  feature_19  \\\n",
      "0   -0.739137    1.802012    1.634606   -0.938180   -1.267337   -1.276334   \n",
      "1    0.732492   -0.872002   -1.654887   -1.130204   -0.122709    0.693431   \n",
      "2   -0.598279    0.019832    0.613460   -1.779439    0.830498   -0.737332   \n",
      "3   -1.190917   -1.442381   -0.929136   -0.221600   -0.346772    0.034246   \n",
      "4    1.068379   -0.882271    2.303639   -0.973379    1.259233    0.360015   \n",
      "\n",
      "   feature_20  label  \n",
      "0    1.016643      1  \n",
      "1    0.911363      0  \n",
      "2   -0.578212      1  \n",
      "3   -1.040199      1  \n",
      "4    1.920368      0  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Model: BRFC \t AUC: 0.90 Kappa:80.07 g-mean: 0.90\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Generate the dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(X, columns=[f'feature_{i+1}' for i in range(X.shape[1])])\n",
    "df['label'] = y\n",
    "\n",
    "print(df.head())\n",
    "\n",
    "clf = BalancedRandomForestClassifierWrapper(\"BRFC\", 'label')\n",
    "clf.evaluate(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 21 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   feature_1   1000 non-null   float64\n",
      " 1   feature_2   1000 non-null   float64\n",
      " 2   feature_3   1000 non-null   float64\n",
      " 3   feature_4   1000 non-null   float64\n",
      " 4   feature_5   1000 non-null   float64\n",
      " 5   feature_6   1000 non-null   float64\n",
      " 6   feature_7   1000 non-null   float64\n",
      " 7   feature_8   1000 non-null   float64\n",
      " 8   feature_9   1000 non-null   float64\n",
      " 9   feature_10  1000 non-null   float64\n",
      " 10  feature_11  1000 non-null   float64\n",
      " 11  feature_12  1000 non-null   float64\n",
      " 12  feature_13  1000 non-null   float64\n",
      " 13  feature_14  1000 non-null   float64\n",
      " 14  feature_15  1000 non-null   float64\n",
      " 15  feature_16  1000 non-null   float64\n",
      " 16  feature_17  1000 non-null   float64\n",
      " 17  feature_18  1000 non-null   float64\n",
      " 18  feature_19  1000 non-null   float64\n",
      " 19  feature_20  1000 non-null   float64\n",
      " 20  label       1000 non-null   int64  \n",
      "dtypes: float64(20), int64(1)\n",
      "memory usage: 164.2 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    500\n",
       "0    500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
